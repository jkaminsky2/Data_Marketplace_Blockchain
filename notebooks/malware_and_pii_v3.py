#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This code takes in a df_path, checks it for malware, and then scans for and cleans personal identifiable information (PII). If very sensitive PII is found, like social security numbers, individuals get 3 strikes before 0.5 ETH is burned from their account for the violation. If there is no violation, the dataframe is uploaded to the IPFS.
# Either returns an error or states that the dataframe was uploaded to the IPFS.

# Import statements
get_ipython().system('pip3 install requests')
get_ipython().system('pip3 install json')
get_ipython().system('pip3 install pandas')
get_ipython().system('pip3 install re')
get_ipython().system('pip3 install argparse')
get_ipython().system('pip3 install spacy')
get_ipython().system('pip3 install chardet')
get_ipython().system('pip3 install numpy')

import requests
import json
import pandas as pd
import re
import argparse
import spacy
import chardet
import numpy as np

# Load the SpaCy model
nlp = spacy.load("en_core_web_sm")



# Main function to carry out functions, as described before.
def df_scan_and_clean(df_path):
    initial_scan = check_for_malicious(df_path)
    if initial_scan['Unusual Character Rows Count'].item() + initial_scan['Suspicious Keywords'].item() + initial_scan['Suspicious Shell Commands'].item() + initial_scan['Suspicious HTML and JS Tags'].item() > 0:
        raise Exception("Malicious or suspicious content. Please remove unusual characters, shell commands, HTML and JS tags, and/or suspicious keywords like 'os.system' and start over.")
    else:
        # Clean data
        df_to_send = clean_pii(df_path)
        # Upload to IPFS
        print("Uploaded to IPFS")
        


# Check for malicious content
def check_for_malicious(df_path):
    # Open file
    with open(df_path, 'rb') as f:
        result = chardet.detect(f.read())

    df = pd.read_csv(df_path, encoding=result['encoding'])

    suspicious_keywords = r'\b(?:eval|exec\b(?!utive)|import\b|os\.system|subprocess|popen|pickle|base64|__import__|lambda)\b'
    shell_commands = r'(\b(?:rm|mv|cp|ls|cat|curl|wget|chmod|chown|kill)\b|&&|\||;)'
    html_js_tags = r'(<script>|<iframe>|<img>|onerror|onclick|onload)'


    # Check for unusual characters
    unusual_characters = r'[^\x20-\x7E]'  # Matches non-ASCII characters outside normal visible range
    unusual_char_rows_count = df.apply(lambda row: row.astype(str).str.contains(unusual_characters).any(), axis=1).sum()

    # Identify suspicious cells per column
    suspicious_cells = {}
    for col in df.columns:

        # Check for suspicious patterns (malicious content indicators)
        keyword_matches = df[col].astype(str).str.contains(suspicious_keywords, case=False, na=False).sum()
        shell_command_matches = df[col].astype(str).str.contains(shell_commands, case=False, na=False).sum()
        html_js_tag_matches = df[col].astype(str).str.contains(html_js_tags, case=False, na=False).sum()

        if 'Suspicious Keywords' not in suspicious_cells.keys():
            total_keyword_matches = keyword_matches
            total_shell_command_matches = shell_command_matches
            total_html_js_tag_matches = html_js_tag_matches
        else:
            total_keyword_matches += keyword_matches
            total_shell_command_matches += shell_command_matches
            total_html_js_tag_matches += html_js_tag_matches

    # Summary of suspicious content checks
    results = {
        'Encoding': result['encoding'],
        'Unusual Character Rows Count': unusual_char_rows_count,
        'Suspicious Keywords': total_keyword_matches,
        'Suspicious Shell Commands': total_shell_command_matches,
        'Suspicious HTML and JS Tags': total_html_js_tag_matches
    }


    return results

# Function to iterate through the df to clean the entire df. Returns the cleaned df
def clean_pii(df_link):
    offenses = 0
    
    # Read in the safe df_link
    df = pd.read_csv(df_link)
    cast_type = True

    # Clean column by column; if dangerous PII is found, break off and do not return the df
    for column in df.columns:
        try:
            df[column] = df[column].apply(pii_finder)
        except Exception as e: 
            offenses += 1
            cast_type = False
            print(f"Error processing column '{column}': {e}")
            break 

    # Burn user's ETH if they try to sell too many dataframes containing PII. 
    if offenses > 3:
        # Placeholder for further action
        print("Too many offenses found, further action required.")

    # Cast columns to the correct type
    if cast_type:
        for column in df.columns:
            try:
                df[column] = pd.to_numeric(df[column], errors='coerce')
            except ValueError:
                try:
                    df[column] = pd.to_datetime(df[column], errors='coerce')
                except ValueError:
                    if df[column].str.lower().isin(['true', 'false']).all():
                        df[column] = df[column].str.lower() == 'true'
                    else:
                        pass
    return df

# Function to locate and fix PII by cell. Returns the cleaned text.
def pii_finder(text):
    # Convert the cell to a string to use regex
    if not isinstance(text, str):
        text = str(text)
        
    about_people = False

    # Check for SQL Injection
    sql_patterns = [
        r"(?i)\b(SELECT\s+\*?\s+FROM|INSERT\s+INTO|UPDATE\s+\w+\s+SET|DELETE\s+FROM)\b", 
        r"(?i)\b(ALTER\s+TABLE|DROP\s+TABLE|CREATE\s+TABLE|UNION\s+SELECT)\b"
    ]

    for pattern in sql_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            raise Exception("SQL Injection Detected; please remove. Failure to do so again will result in a 0.5 ETH penalty.")

    
    # Regex patterns
    patterns = {
        "email_address": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",
        "phone_number": r"\b(?:\+?\d{1,3}\s?)?\(?\d{3}\)?[-\s]?\d{3}[-\s]?\d{4}\b",
        "ssn": r"\b\d{3}[-]?\d{2}[-]?\d{4}\b",
        "ip_address": r"\b(?:(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9]?[0-9])|(?:[0-9A-Fa-f]{1,4}:){7}[0-9A-Fa-f]{1,4})\b",
        "last_name": r"\b([A-Z][a-z]+(?:\s[Jr\.|Sr\.|II|III|IV])?)\b",
        "credit_card": r"\b(?:\d{4}[-\s]?){3}\d{4}|\b(?:\d{4}[-\s]?){3}\d{3}\b|\b(?:\d{4}[-\s]?){2}\d{4}[-\s]?\d{4}\b|\b\d{13,19}\b",
        "age": r"\b(?:(?:age|around|approximately|about|was|were)\s*)?(1[01]?[0-9]|[1-9]?\d)(?:\s*years?\s*(?:\d+\s*days?)?\s*old|\s*yrs?\.?|old)?\b",
        "birth_date": r"\b(\d{4}[-/]\d{1,2}[-/]\d{1,2}|\d{1,2}[-/]\d{1,2}[-/]\d{4})\b"
    }

    # Goes regex by regex to make sure no PII is missed.
    for category, pattern in patterns.items():
        matches = re.finditer(pattern, text)
        
        if category == "phone_number" and any(matches):
            return "[REDACTED PHONE NUMBER]"
        
        elif category == "email_address" and any(matches):
            return "[REDACTED EMAIL]"
        
        # Raise errors and not return the df if dangerous PII like SSN, ip_address, and credit card info is found.
        elif category == "ssn" and any(matches):
            raise Exception("SSNs Included; please remove. Failure to do so again will result in a 0.5 ETH penalty.")
        
        elif category == "ip_address" and any(matches):
            raise Exception("IP Addresses Included; please remove. Failure to do so again will result in a 0.5 ETH penalty.")
        
        elif category == 'credit_card' and any(matches):
            raise Exception("Credit Card Information Detected; please remove. Failure to do so again will result in a 0.5 ETH penalty.")
        
        elif category == 'last_name':            
            about_people, cleaned = replace_last_names(text)
            return cleaned
        
        elif category == 'age' and about_people and any(matches):
            return "[REDACTED AGE]"
        
        elif category == 'birth_date' and about_people and any(matches):
            return "[REDACTED BIRTH DATE]"
        
        else:
            return text
        
# Function to clean last names, if they are found. For example, the name "John Smith" would be converted to "John S.". Returns the cleaned name and True if a name is detected, else False. 
def replace_last_names(text):
    modified_text = text
    people = False

    # Uses the natural language processor (NLP) to find potential names
    for ent in nlp(text).ents:
        if ent.label_ == "PERSON":
            name_parts = ent.text.split()
            if len(name_parts) > 1:  # Ensure there's 1+ last names, then converts the text
                people = True
                last_name = name_parts[-1]
                anonymized_name = name_parts[0] + " " + last_name[0] + "."
                modified_text = modified_text.replace(ent.text, anonymized_name)

    return people, modified_text

# Main function to call all the data
def main():
    parser = argparse.ArgumentParser(description='Scan and clean a CSV file for PII.')
    parser.add_argument('df_link', type=str, help='The link to the CSV file to be processed.')
    args = parser.parse_args()

    # Run the main function
    df_scan_and_clean(args.df_link)

if __name__ == "__main__":
    main()

